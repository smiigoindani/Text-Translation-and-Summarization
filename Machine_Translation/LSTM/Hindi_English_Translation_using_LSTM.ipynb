{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Neural Machine Translation using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhoLQDkGgdx8"
      },
      "source": [
        "#Make imports\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import seaborn as sns\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ockyMCIm-3q5",
        "outputId": "597fb132-742e-460b-ffd5-341c76dee6b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQNeTtWZlwUc",
        "outputId": "86a32034-d28e-4d3c-f729-3e6d8fa422e7"
      },
      "source": [
        "#TPU settings\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Tensorflow version 2.8.2\n",
            "Running on TPU  ['10.87.82.234:8470']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-_bF5bilI2f"
      },
      "source": [
        "def preprocess(text):\n",
        "  text = ''.join(ch for ch in text if ch not in string.punctuation)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\d','',text)\n",
        "  text = re.sub(r'\\s+',' ',text)\n",
        "  text = text.strip()\n",
        "  return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKe9ncQoZfox"
      },
      "source": [
        "#Extract dataset and preprocess\n",
        "dataset_root = \"./drive/MyDrive/ml/\"\n",
        "\n",
        "if os.path.exists(dataset_root + \"parallel/preprocessed_data.pickle\"):\n",
        "  with open(dataset_root + \"parallel/preprocessed_data.pickle\", 'rb') as f:\n",
        "    english_sentences, hindi_sentences = pickle.load(f)\n",
        "else:\n",
        "  if not os.path.exists(dataset_root + \"parallel/IITB.en-hi.en\"):\n",
        "    os.system(\"tar -xzf \" + dataset_root + \"parallel.tgz -C \" + dataset_root)\n",
        "\n",
        "  with open(dataset_root + \"test.en\",'r') as f:\n",
        "    english_sentences = f.read().split('\\n')\n",
        "\n",
        "  with open(dataset_root + \"test.hi\",'r') as f:\n",
        "    hindi_sentences = f.read().split('\\n')\n",
        "\n",
        "  english_sentences = [preprocess(en) for en in english_sentences]\n",
        "  hindi_sentences = ['<START> ' + re.sub('[a-zA-Z]','',preprocess(hi)) + ' <END>' for hi in hindi_sentences]\n",
        "\n",
        "  #Remove duplicate sentences\n",
        "  english_unique = set()\n",
        "  english_sentences_temp = []\n",
        "  hindi_sentences_temp = []\n",
        "  l = len(english_sentences)\n",
        "  for i in range(l):\n",
        "    if english_sentences[i] not in english_unique:\n",
        "      english_unique.add(english_sentences[i])\n",
        "      english_sentences_temp.append(english_sentences[i])\n",
        "      hindi_sentences_temp.append(hindi_sentences[i])\n",
        "\n",
        "  english_sentences = english_sentences_temp\n",
        "  hindi_sentences = hindi_sentences_temp\n",
        "  \n",
        "  with open(dataset_root + \"preprocessed_data.pickle\",'wb') as f:\n",
        "    pickle.dump((english_sentences, hindi_sentences), f)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsf6EbkWZDUY",
        "outputId": "91b89aa8-e29d-43fb-ca8f-c02fc4ea6cb9"
      },
      "source": [
        "print(len(english_sentences), len(hindi_sentences))\n",
        "print()\n",
        "english_sentences[:3], hindi_sentences[:3]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998998 998998\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['on the sidelines of this event i hope the delegates joining us from abroad shall have some time to see the history and splendour of delhi',\n",
              "  'we are proud to be the global host for world environment day',\n",
              "  'we are also committed to ensure that we do so in a way that is sustainable and green'],\n",
              " ['<START> मुझे उम्मीद है कि विदेशों से आए प्रतिनिधियों के पास दिल्ली के इतिहास और गौरव को देखने के लिए कुछ समय मिलेगा। <END>',\n",
              "  '<START> हमें विश्व पर्यावरण दिवस के लिए वैश्विक मेजबान बनने का गर्व है। <END>',\n",
              "  '<START> हम वह करने के लिए संकल्पबद्ध हैं जो सतत् औऱ हरित है। <END>'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjnK8XArDPUe"
      },
      "source": [
        "#Some parameters\n",
        "vocab_size = 10000\n",
        "total_sentences = 25000\n",
        "maxlen = 10\n",
        "epochs = 70\n",
        "validation_split = 0.05"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyHjYB_eMpD7"
      },
      "source": [
        "en_data = []\n",
        "hi_data = []\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "for (en,hi) in zip(english_sentences, hindi_sentences):\n",
        "  l = min(len(en.split()), len(hi.split()))\n",
        "  if l <= maxlen:\n",
        "    en_data.append(en)\n",
        "    hi_data.append(hi)\n",
        "    cnt += 1\n",
        "  if cnt == total_sentences:\n",
        "    break"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwR2rlOvB-xZ",
        "outputId": "a173430a-3ffa-4892-9876-d359abe493a2"
      },
      "source": [
        "#Tokenize the texts and convert to sequences\n",
        "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>', lower=False)\n",
        "en_tokenizer.fit_on_texts(en_data)\n",
        "en_sequences = en_tokenizer.texts_to_sequences(en_data)\n",
        "\n",
        "hi_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<OOV>', lower=False)\n",
        "hi_tokenizer.fit_on_texts(hi_data)\n",
        "hi_sequences = hi_tokenizer.texts_to_sequences(hi_data)\n",
        "\n",
        "english_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "hindi_vocab_size = len(hi_tokenizer.word_index) + 1\n",
        "print(\"English Vocab Size: \", english_vocab_size)\n",
        "print(\"Hindi Vocab Size: \", hindi_vocab_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab Size:  1579\n",
            "Hindi Vocab Size:  1672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luUa7TE6RYFq"
      },
      "source": [
        "#Prepare encoder data\n",
        "encoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(en_sequences, maxlen=maxlen, padding='post')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olIjin62TPF7"
      },
      "source": [
        "#Prepare decoder data\n",
        "decoder_inputs = []\n",
        "decoder_outputs = []\n",
        "\n",
        "for hi in hi_sequences:\n",
        "  decoder_inputs.append(hi[:-1])\n",
        "  decoder_outputs.append(hi[1:])\n",
        "\n",
        "decoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_inputs, maxlen=maxlen, padding='post')\n",
        "decoder_outputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_outputs, maxlen=maxlen, padding='post')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5OWbUrPRENr",
        "outputId": "620ca379-a083-4c6e-8958-b5895eba8b26"
      },
      "source": [
        "# Training and Testing split\n",
        "# 80%, 20%\n",
        "split = int(0.80 * total_sentences)\n",
        "\n",
        "X_train = [encoder_inputs[:split], decoder_inputs[:split]]\n",
        "y_train = decoder_outputs[:split]\n",
        "\n",
        "# Test data to evaluate our NMT model using BLEU score\n",
        "X_test = en_data[:split]\n",
        "y_test = hi_data[:split]\n",
        "\n",
        "print(X_train[0].shape, X_train[1].shape, y_train.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23750, 10) (23750, 10) (23750, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUboXx8WjDnP",
        "outputId": "e4e233eb-44c7-463e-8ce9-a76447736de6"
      },
      "source": [
        "#Define LSTM model\n",
        "d_model = 256\n",
        "\n",
        "#Encoder\n",
        "inputs = tf.keras.layers.Input(shape=(None,))\n",
        "x = tf.keras.layers.Embedding(english_vocab_size, d_model, mask_zero=True)(inputs)\n",
        "_,state_h,state_c = tf.keras.layers.LSTM(d_model,activation='relu',return_state=True)(x)\n",
        "\n",
        "#Decoder\n",
        "targets = tf.keras.layers.Input(shape=(None,))\n",
        "embedding_layer = tf.keras.layers.Embedding(hindi_vocab_size, d_model, mask_zero=True)\n",
        "x = embedding_layer(targets)\n",
        "decoder_lstm = tf.keras.layers.LSTM(d_model,activation='relu',return_sequences=True, return_state=True)\n",
        "x,_,_ = decoder_lstm(x, initial_state=[state_h, state_c])\n",
        "dense1 = tf.keras.layers.Dense(hindi_vocab_size, activation='softmax')\n",
        "x = dense1(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[inputs, targets],outputs=x)\n",
        "model.summary()\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    404224      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    428032      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1672)   429704      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,312,584\n",
            "Trainable params: 2,312,584\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq3TUpTK3TRE"
      },
      "source": [
        "#Save model after each epoch\n",
        "save_model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='./drive/MyDrive/ml/en-hi.h5',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max'\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsPj7SL1f-b",
        "outputId": "f1c3ca1e-f8ac-4073-a37d-316a0c2cd1d7"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, callbacks=[save_model_callback, tf.keras.callbacks.TerminateOnNaN()])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "15/15 [==============================] - 6s 118ms/step - loss: 6.9042 - accuracy: 0.0890 - val_loss: 5.3849 - val_accuracy: 0.0495\n",
            "Epoch 2/70\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 5.7596 - accuracy: 0.1056 - val_loss: 5.2145 - val_accuracy: 0.0990\n",
            "Epoch 3/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 5.5400 - accuracy: 0.1116 - val_loss: 5.2294 - val_accuracy: 0.0941\n",
            "Epoch 4/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 5.4814 - accuracy: 0.1191 - val_loss: 5.2989 - val_accuracy: 0.0941\n",
            "Epoch 5/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 5.3303 - accuracy: 0.1351 - val_loss: 5.3231 - val_accuracy: 0.1337\n",
            "Epoch 6/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 5.1616 - accuracy: 0.1406 - val_loss: 5.3273 - val_accuracy: 0.1337\n",
            "Epoch 7/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 5.0320 - accuracy: 0.1445 - val_loss: 5.2744 - val_accuracy: 0.1386\n",
            "Epoch 8/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 4.9283 - accuracy: 0.1605 - val_loss: 5.3097 - val_accuracy: 0.1436\n",
            "Epoch 9/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 4.8566 - accuracy: 0.1681 - val_loss: 5.4798 - val_accuracy: 0.1386\n",
            "Epoch 10/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 4.7616 - accuracy: 0.1731 - val_loss: 5.3705 - val_accuracy: 0.1287\n",
            "Epoch 11/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 4.6860 - accuracy: 0.1743 - val_loss: 5.5438 - val_accuracy: 0.1188\n",
            "Epoch 12/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 4.6168 - accuracy: 0.1752 - val_loss: 5.8075 - val_accuracy: 0.1139\n",
            "Epoch 13/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 4.5221 - accuracy: 0.1804 - val_loss: 5.8669 - val_accuracy: 0.1139\n",
            "Epoch 14/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 4.4481 - accuracy: 0.1859 - val_loss: 5.9222 - val_accuracy: 0.1238\n",
            "Epoch 15/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 4.3553 - accuracy: 0.1941 - val_loss: 5.9153 - val_accuracy: 0.1238\n",
            "Epoch 16/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 4.2636 - accuracy: 0.1983 - val_loss: 5.8811 - val_accuracy: 0.1139\n",
            "Epoch 17/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 4.1728 - accuracy: 0.2026 - val_loss: 5.9759 - val_accuracy: 0.1386\n",
            "Epoch 18/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 4.0700 - accuracy: 0.2081 - val_loss: 6.0915 - val_accuracy: 0.1287\n",
            "Epoch 19/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 3.9715 - accuracy: 0.2186 - val_loss: 6.4759 - val_accuracy: 0.1089\n",
            "Epoch 20/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 3.8596 - accuracy: 0.2223 - val_loss: 6.4892 - val_accuracy: 0.0941\n",
            "Epoch 21/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 3.7546 - accuracy: 0.2314 - val_loss: 6.9011 - val_accuracy: 0.1139\n",
            "Epoch 22/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 3.6515 - accuracy: 0.2408 - val_loss: 6.9879 - val_accuracy: 0.1188\n",
            "Epoch 23/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 3.5193 - accuracy: 0.2474 - val_loss: 7.5425 - val_accuracy: 0.1139\n",
            "Epoch 24/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 3.4020 - accuracy: 0.2545 - val_loss: 7.7005 - val_accuracy: 0.1089\n",
            "Epoch 25/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 3.2594 - accuracy: 0.2685 - val_loss: 7.6314 - val_accuracy: 0.1238\n",
            "Epoch 26/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 3.1170 - accuracy: 0.2820 - val_loss: 8.1316 - val_accuracy: 0.1238\n",
            "Epoch 27/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 2.9739 - accuracy: 0.2941 - val_loss: 9.1679 - val_accuracy: 0.1188\n",
            "Epoch 28/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 2.8350 - accuracy: 0.3156 - val_loss: 9.2151 - val_accuracy: 0.1089\n",
            "Epoch 29/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 2.6890 - accuracy: 0.3368 - val_loss: 9.9824 - val_accuracy: 0.1238\n",
            "Epoch 30/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 2.5110 - accuracy: 0.3666 - val_loss: 10.8079 - val_accuracy: 0.1139\n",
            "Epoch 31/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 2.3999 - accuracy: 0.3858 - val_loss: 11.0941 - val_accuracy: 0.1386\n",
            "Epoch 32/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 2.2237 - accuracy: 0.4274 - val_loss: 12.7249 - val_accuracy: 0.1238\n",
            "Epoch 33/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 2.0916 - accuracy: 0.4477 - val_loss: 12.6481 - val_accuracy: 0.1188\n",
            "Epoch 34/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 1.9422 - accuracy: 0.4951 - val_loss: 13.2027 - val_accuracy: 0.1139\n",
            "Epoch 35/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 1.8712 - accuracy: 0.5086 - val_loss: 13.1198 - val_accuracy: 0.1089\n",
            "Epoch 36/70\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 1.6929 - accuracy: 0.5529 - val_loss: 13.7542 - val_accuracy: 0.1139\n",
            "Epoch 37/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 1.6314 - accuracy: 0.5694 - val_loss: 13.8079 - val_accuracy: 0.1139\n",
            "Epoch 38/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 1.4338 - accuracy: 0.6270 - val_loss: 16.6385 - val_accuracy: 0.1040\n",
            "Epoch 39/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 1.4301 - accuracy: 0.6165 - val_loss: 16.4020 - val_accuracy: 0.1139\n",
            "Epoch 40/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 1.2461 - accuracy: 0.6707 - val_loss: 16.9523 - val_accuracy: 0.1337\n",
            "Epoch 41/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 1.2032 - accuracy: 0.6867 - val_loss: 18.4469 - val_accuracy: 0.1485\n",
            "Epoch 42/70\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 1.0642 - accuracy: 0.7171 - val_loss: 18.0084 - val_accuracy: 0.1337\n",
            "Epoch 43/70\n",
            "15/15 [==============================] - 1s 81ms/step - loss: 1.0814 - accuracy: 0.7206 - val_loss: 17.9833 - val_accuracy: 0.1188\n",
            "Epoch 44/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.9175 - accuracy: 0.7583 - val_loss: 18.3180 - val_accuracy: 0.1188\n",
            "Epoch 45/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.9016 - accuracy: 0.7709 - val_loss: 19.1548 - val_accuracy: 0.1287\n",
            "Epoch 46/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.7988 - accuracy: 0.7910 - val_loss: 19.1434 - val_accuracy: 0.1386\n",
            "Epoch 47/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.8668 - accuracy: 0.7839 - val_loss: 17.4292 - val_accuracy: 0.1386\n",
            "Epoch 48/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.6891 - accuracy: 0.8292 - val_loss: 20.2105 - val_accuracy: 0.1337\n",
            "Epoch 49/70\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.5973 - accuracy: 0.8495 - val_loss: 21.4814 - val_accuracy: 0.1238\n",
            "Epoch 50/70\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.5791 - accuracy: 0.8557 - val_loss: 20.0805 - val_accuracy: 0.1238\n",
            "Epoch 51/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.6064 - accuracy: 0.8635 - val_loss: 20.6116 - val_accuracy: 0.1485\n",
            "Epoch 52/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.5694 - accuracy: 0.8601 - val_loss: 19.7381 - val_accuracy: 0.1386\n",
            "Epoch 53/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.4321 - accuracy: 0.8948 - val_loss: 21.5037 - val_accuracy: 0.1238\n",
            "Epoch 54/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.4632 - accuracy: 0.8898 - val_loss: 19.2515 - val_accuracy: 0.1287\n",
            "Epoch 55/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.3631 - accuracy: 0.9147 - val_loss: 21.1203 - val_accuracy: 0.1386\n",
            "Epoch 56/70\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.3578 - accuracy: 0.9122 - val_loss: 21.1453 - val_accuracy: 0.1287\n",
            "Epoch 57/70\n",
            "15/15 [==============================] - 1s 77ms/step - loss: 0.3538 - accuracy: 0.9113 - val_loss: 19.7197 - val_accuracy: 0.1188\n",
            "Epoch 58/70\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.3252 - accuracy: 0.9268 - val_loss: 21.0160 - val_accuracy: 0.1287\n",
            "Epoch 59/70\n",
            "15/15 [==============================] - 1s 67ms/step - loss: 0.2302 - accuracy: 0.9495 - val_loss: 22.9565 - val_accuracy: 0.1238\n",
            "Epoch 60/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 0.3262 - accuracy: 0.9190 - val_loss: 20.2029 - val_accuracy: 0.1188\n",
            "Epoch 61/70\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.1929 - accuracy: 0.9611 - val_loss: 23.5357 - val_accuracy: 0.1238\n",
            "Epoch 62/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.1703 - accuracy: 0.9625 - val_loss: 24.9089 - val_accuracy: 0.1139\n",
            "Epoch 63/70\n",
            "15/15 [==============================] - 1s 77ms/step - loss: 0.2664 - accuracy: 0.9428 - val_loss: 22.3035 - val_accuracy: 0.1238\n",
            "Epoch 64/70\n",
            "15/15 [==============================] - 1s 77ms/step - loss: 0.1659 - accuracy: 0.9646 - val_loss: 23.2279 - val_accuracy: 0.1287\n",
            "Epoch 65/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.1780 - accuracy: 0.9662 - val_loss: 22.1743 - val_accuracy: 0.1287\n",
            "Epoch 66/70\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 0.1730 - accuracy: 0.9577 - val_loss: 18.8581 - val_accuracy: 0.1040\n",
            "Epoch 67/70\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.1257 - accuracy: 0.9824 - val_loss: 23.0534 - val_accuracy: 0.1337\n",
            "Epoch 68/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.2052 - accuracy: 0.9591 - val_loss: 21.9490 - val_accuracy: 0.1337\n",
            "Epoch 69/70\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.0649 - accuracy: 0.9922 - val_loss: 23.4003 - val_accuracy: 0.1337\n",
            "Epoch 70/70\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 0.0598 - accuracy: 0.9911 - val_loss: 24.2011 - val_accuracy: 0.1188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4b61c4710>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx0r37V9fshH",
        "outputId": "358ccc3a-381c-446e-d68a-ff77ccb67783"
      },
      "source": [
        "#Retrieve previously saved stuff\n",
        "saved_model = tf.keras.models.load_model('./drive/MyDrive/ml/en-hi.h5')\n",
        "\n",
        "saved_model.summary()\n",
        "\n",
        "inputs = saved_model.get_layer('input_1').output\n",
        "_,state_h,state_c = saved_model.get_layer('lstm').output\n",
        "targets = saved_model.get_layer('input_2').output\n",
        "embedding_layer = saved_model.get_layer('embedding_1')\n",
        "decoder_lstm = saved_model.get_layer('lstm_1')\n",
        "dense1 = saved_model.get_layer('dense')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    404224      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    428032      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1672)   429704      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,312,584\n",
            "Trainable params: 2,312,584\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBvZo1SRzHbU"
      },
      "source": [
        "#Inference Model\n",
        "\n",
        "#Encoder\n",
        "encoder = tf.keras.models.Model(inputs, [state_h, state_c])\n",
        "\n",
        "#Decoder\n",
        "decoder_input_h = tf.keras.layers.Input(shape=(d_model,))\n",
        "decoder_input_c = tf.keras.layers.Input(shape=(d_model,))\n",
        "x = embedding_layer(targets)\n",
        "x, decoder_output_h, decoder_output_c = decoder_lstm(x, initial_state=[decoder_input_h, decoder_input_c])\n",
        "x = dense1(x)\n",
        "decoder = tf.keras.models.Model([targets] + [decoder_input_h, decoder_input_c], \n",
        "                                [x] + [decoder_output_h, decoder_output_c])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM4WlWIkXbS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76159749-1149-453b-cea8-7d7504ad013f"
      },
      "source": [
        "def predict_sentence(en_input):\n",
        "  input_seq = en_tokenizer.texts_to_sequences([en_input])\n",
        "\n",
        "  next_h, next_c = encoder.predict(input_seq)\n",
        "\n",
        "  curr_token = np.zeros(1)\n",
        "  curr_token[0] = hi_tokenizer.word_index['<START>']\n",
        "\n",
        "  pred_sentence = ''\n",
        "\n",
        "  for i in range(maxlen):\n",
        "    output, next_h, next_c = decoder.predict([curr_token] + [next_h, next_c])\n",
        "    next_token = np.argmax(output[0, 0, :])\n",
        "    next_word = hi_tokenizer.index_word[next_token]\n",
        "    if next_word == '<END>':\n",
        "      break\n",
        "    else:\n",
        "      pred_sentence += ' ' + next_word\n",
        "      curr_token[0] = next_token\n",
        "\n",
        "  return pred_sentence"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original output:  give your application an accessibility workout\n",
            "Input:   अपने अनुप्रयोग को पहुंचनीयता करें\n",
            "Prediction:  your application has to do access workout\n",
            "\n",
            "Original output:  accerciser accessibility explorer\n",
            "Input:   एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
            "Prediction:  exerciser access explorer\n",
            "\n",
            "Original output:  the default plugin layout for the bottom panel\n",
            "Input:   ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका\n",
            "Prediction:  default plugin layout for upper upper\n",
            "\n",
            "Original output:  a list of plugins that are disabled by default\n",
            "Input:   उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है \n",
            "Prediction: list disabled by defaulted list of of plugins \n",
            "\n",
            "Original output:  highlight duration\n",
            "Input:   अवधि को हाइलाइट रकें\n",
            "Prediction:  duration keep highlighted\n",
            "\n",
            "Original output:  the duration of the highlight box when selecting accessible nodes\n",
            "Input:   पहुंचनीय आसंधि नोड को चुनते समय हाइलाइट बक्से की अवधि\n",
            "Prediction:  permission given nodes to certified highlight box of of\n",
            "\n",
            "Original output:  highlight border color\n",
            "Input:   सीमांत बोर्डर के रंग को हाइलाइट करें\n",
            "Prediction:  border color gain\n",
            "\n",
            "Original output:  the color and opacity of the highlight border\n",
            "Input:   हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।\n",
            "Prediction:  color and opacity of the highlight border\n",
            "\n"
          ]
        }
      ]
    }
  ]
}